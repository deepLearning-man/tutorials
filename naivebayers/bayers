def loadDataSet() :
    postingList = [['my' , 'dog' , 'has' , 'flea' , 'problems' , 'help' , 'please'] ,
                   ['maybe' , 'not' , 'take' , 'him' , 'to' , 'dog' , 'park' , 'stupid'] ,
                   ['my' , 'dalmation' , 'is' , 'so' , 'cute' , 'I' , 'love' , 'him'] ,
                   ['stop' , 'posting' , 'stupid' , 'worthless' , 'garbage'] ,
                   ['mr' , 'licks' , 'ate' , 'my' , 'steak' , 'how' , 'to' , 'stop' , 'him'] ,
                   ['quit' , 'buying' , 'worthless' , 'dog' , 'food' , 'stupid']]
    classVec = [0 , 1 , 0 , 1 , 0 , 1]
    return postingList , classVec


def createVocabList(dataset) :
    vocabSet = set([])
    for document in dataset :
        # 创建两个集合的并集
        vocabSet = vocabSet | set(document)
    return list(vocabSet)


def setOfWords2Vec(vocablist , inputset) :
    returnVec = [0] * len(vocablist)
    for word in inputset :
        if word in vocablist :
            # 这里如果词出现就为1，不出现就为0，出现多次仍为1
            returnVec[vocablist.index(word)] = 1
        else :
            print("the word: %s is not in my Vocabulary!" % word)
    return returnVec


listOPosts , listClasses = loadDataSet()
myVocabList = createVocabList(listOPosts)
print(myVocabList)
print(setOfWords2Vec(myVocabList , listOPosts[0]))

# OUTPUTS:
# ['dalmation', 'worthless', 'buying', 'steak', 'mr', 'ate', 'park', 'my', 'take', 'is', 'not', 'love', 'stop', 'licks', 'dog', 'problems', 'food', 'please', 'to', 'flea', 'so', 'how', 'maybe', 'has', 'posting', 'I', 'quit', 'him', 'cute', 'stupid', 'help', 'garbage']
# [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0]
import numpy as np


def trainNB0(trainMatrix , trainCategory) :
    numTrainDocs = len(trainMatrix)
    numWords = len(trainMatrix[0])
    # 侮辱性文档，即class为1，P(1)的基础概率
    pAbusive = sum(trainCategory) / float(numTrainDocs)
    p0Num = np.ones(numWords);    p1Num = np.ones(numWords)
    p0Denom = 2.0;    p1Denom = 2.0
    for i in range(numTrainDocs) :
        # 遍历每个文档，其对应的种类piNum的对应词位置数量相加，对应种类piDenom总词数量相加
        if trainCategory[i] == 1 :
            p1Num += trainMatrix[i]
            p1Denom += sum(trainMatrix[i])
        else :
            p0Num += trainMatrix[i]
            p0Denom += sum(trainMatrix[i])
    p1Vect=np.log(p1Num/p1Denom)
    p0Vect=np.log(p0Num/p0Denom)
    return p0Vect,p1Vect,pAbusive

trainMat=[ ]
for postinDoc in listOPosts:
    trainMat.append(setOfWords2Vec(myVocabList,postinDoc))

p0V,p1V,pAb=trainNB0(trainMat,listClasses)
print(pAb)
print(p0V)
print(p1V)
# OUTPUTS:
# 0.5
# [0.04166667 0.         0.04166667 0.04166667 0.04166667 0.04166667
#  0.04166667 0.125      0.04166667 0.         0.04166667 0.
#  0.04166667 0.04166667 0.         0.08333333 0.04166667 0.
#  0.04166667 0.         0.04166667 0.04166667 0.04166667 0.
#  0.         0.04166667 0.         0.04166667 0.04166667 0.04166667
#  0.         0.        ]
# [0.         0.05263158 0.         0.         0.         0.10526316
#  0.         0.         0.         0.05263158 0.         0.15789474
#  0.05263158 0.         0.05263158 0.05263158 0.         0.10526316
#  0.         0.05263158 0.         0.         0.         0.05263158
#  0.05263158 0.05263158 0.05263158 0.         0.         0.
#  0.05263158 0.05263158]

def classifyNB(vec2Classify,p0Vec,p1Vec,pClass1):
    #这里vec2Classify和p1Vec是对应元素相乘，不是矩阵相乘
    p1=sum(vec2Classify*p1Vec)+np.log(pClass1)
    p0=sum(vec2Classify*p0Vec)+np.log(1-pClass1)
    if p1>p0:
        return 1
    else:
        return 0
def testingNB():
    listOPosts,listClasses=loadDataSet()
    myVocabList=createVocabList(listOPosts)
    trainMat=[]
    for postinDoc in listOPosts:
        trainMat.append(setOfWords2Vec(myVocabList,postinDoc))
    p0V,p1V,pAb=trainNB0(trainMat,listClasses)
    testEntry=['love','my','dalmation']
    thisDoc=setOfWords2Vec(myVocabList,testEntry)
    print("{} classified as: {}".format(testEntry,classifyNB(thisDoc,p0V,p1V,pAb)))
    testEntry=['stupid','garbage']
    thisDoc = setOfWords2Vec(myVocabList , testEntry)
    print("{} classified as: {}".format(testEntry , classifyNB(thisDoc , p0V , p1V , pAb)))
testingNB()
# OUTPUTS:
# ['love', 'my', 'dalmation'] classified as: 0
# ['stupid', 'garbage'] classified as: 1

def bagOfWords2Vec(vocabList,inputSet):
    returnVec = 0*len(vocabList)
    for word in inputSet:
        if word in vocabList:
            returnVec[vocabList.index(word)]+=1
    return returnVec
